---
published: false
layout: post
current: post
cover: /assets/img/msc/msc-cover.png # Add image post (optional)
navigation: True
title: "Neuroscience Journal: How I Stumbled into Machine Learning"
date: 2015-02-04 13:32:20 +0300
tags: [Publications]
class: post-template
subclass: "post"
author: josephdviviano
---

# The Thalamic Reticular Nucleus: Why I Learned to Code

I was the first person ever to record a fMRI signal from the thalamic reticular nucleus.

The TRN is small inhibitory structure in the brain that is implicated in [attentional filtering](https://www.quantamagazine.org/to-pay-attention-the-brain-uses-filters-not-a-spotlight-20190924/). My boss at the time was the Director of York University's MRI centre, [Keith Schneider](https://www.psych.udel.edu/people/full-list-searchable/kschneider?uid=kschneider&Name=Keith%20Schneider) (and has since moved on to do the same and the University of Delaware), was mostly interested in how the [subcortical regions of the brain contribute to attention](https://www.jneurosci.org/content/31/23/8643.short): our proclivity to devote a lot of computational resources to only a few aspects of the data our brain could potentially access. Francis Crick (yeah, the DNA guy) was [the first person suggest that the thalamus would implement these filters](https://www.newscientist.com/article/dn14869-crick-was-right-about-vision-filter-in-the-brain/) to perform attentional filtering, and this was [confirmed many years later](https://www.nature.com/articles/nature07382) in experiments.

My job was to image this attentional filter in action by recording from the TRN in a person using functional MRI (fMRI). fMRI measures blood flow in the brain (the BOLD signal), in response to neural activity (when I was doing my degree, we still didn't fully understand the relationship between neural activity and the BOLD signal, but now [we much better understand it](https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2019.0630)). The big problem with fMRI is that the signal to noise ratio is low, has a lot of geometric distortions as you crank up the resolution, and it is very susceptible to artifacts caused by movements. So we couldn't just collect a brain scan, we had to collect a lot of very well-controlled, high resolution, noisy images and synthesize them into a functional picture of the TRN the same way [astronomers take pictures of deep space](https://keithwiley.com/astroPhotography/imageStacking.shtml).

There were two big challenges: first, if we wanted to average many events together, we would need a really good idea of a particular event type that would drive TRN activity. We considered an attention switching task, but I found a lot of research that suggested different neural populations have different resonant frequencies, and that those resonant frequencies could be driven by external periodic stimuli, shown both in [humans](https://pubmed.ncbi.nlm.nih.gov/11355381/) and [animals](https://journals.physiology.org/doi/full/10.1152/jn.00388.2011).

To maximize the chance I would find the TRN, I didn't want to rely on human behavior: I decided I just wanted to drive the human retina the same way animal researchers drop an electrode directly into the brain to zap it and record the response. I wanted a regular stimulus that could be down to people over and over again, that would give me a decent response. To do this, I started with something called "retinotopic mapping". The primary visual system in the brain is organized like a reverse projector: different regions of the space in front of you map to specific locations on the cortex and thalamus. They call this the "retinotopic map".

{:refdef: style="text-align: center;"}
![Retinotopy]({{ '/assets/img/msc/retinotopic-drawing.gif' | relative_url }})
{: refdef}

In fact, you can even project simple shapes onto the cortex and read them out using fMRI. A very expensive party trick. People map the "retinotopy" using a spinning disk at a fixed speed. Since they know the speed of the disk, they can look for brain regions that activate periodically at that frequency. My idea was to superimpose a flicker modulation on top of a spinning disk that stepped through frequencies at a different rate:

{:refdef: style="text-align: center;"}
![Stimulus]({{ '/assets/img/msc/stimulus.png' | relative_url }})
{: refdef}

And now for the coolest part: the retinotopic maps of my own lateral geniculate nucleus and thalamic reticular nucleus on top of a very high resolution brain scan:

{:refdef: style="text-align: center;"}
![My Brain]({{ '/assets/img/msc/my-brain.png' | relative_url }})
{: refdef}

Our main finding was the thalamic reticular nucleus seemed to be inhibiting the visual system's lateral geniculate nucleus at particular flicker frequencies: around 10-12 Hz, the lateral geniculate nucleus's activity dominates (corresponding to the "alpha frequency" which is [heavily implicated in visual attention](https://www.jneurosci.org/content/37/42/10173.abstract)), but the thalamic reticular nucleus' activity seemed to be maximal in the 20 - 60 Hz range where the visual system is less active: these frequencies correspond to the "beta/gamma frequencies" and are associated with [top down feedback](https://www.nature.com/articles/s41598-018-25267-1) from non-visual areas ([also see](https://www.jneurosci.org/content/37/28/6698)). It seemed like driving your brain with a high flicker frequency sends shock-waves through your brain and activates an automatic feedback mechanism. I believe it: strobe lights are exciting at concerts for a reason.

Aside from teaching me a tonne about physics and how the brain operates as distributed network, this was the project that taught me the basics of programming, and that kick-started my career. [Here's the paper](https://www.jneurosci.org/content/35/5/2026.abstract).

# A Turn to Clinical Research: A Biomarker of Cognitive Decline

While I was interested in what I was learning about how the brain worked, I struggled to tie my work with anything that would lead to a true decoding of the brain's function, even with substantial improvements in the imaging technology (in hindsight, I was correct). So I began my pivot to clinical neuroscience, where the goal was less to understand mechanistically how the brain works, but rather how it changes in disease.

For decades, functional MRI (fMRI) researchers primarily looked for "task evoked" activity in the brain by looking for small deviations of the BOLD signal against what appeared to be a massive wall of background "noise". The signal to noise ratio (SNR) of the task-evoked BOLD signal is small: only a [few percentage points at 1.5 T](https://onlinelibrary.wiley.com/doi/full/10.1002/1522-2594%28200012%2944%3A6%3C925%3A%3AAID-MRM14%3E3.0.CO%3B2-M), which is a major contributor to the [reproducibility crisis in fMRI studies](https://www.nature.com/articles/s42003-018-0073-z).

In 1995, researchers discovered that areas of the brain's primary motor cortex seemed to have highly correlated BOLD signals with other regions known to be involved with motor output, even when the participant wasn't doing anything: they called this "[functional connectivity](https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.1910340409)". At first, this "resting state" signal was written off as uninteresting noise. The research over the next two decades would find irrefutable evidence that [the resting state signal is highly reproducible](https://www.pnas.org/content/103/37/13848.short) and that [they form networks that have a tight correspondence with the regions identified in the task-based fMRI literature](https://www.pnas.org/content/106/31/13040.short). This made them a prime candidate for a _psychiatric biomarker_.

{:refdef: style="text-align: center;"}
![Resting State Networks]({{ '/assets/img/rest/rest-task.png' | relative_url }})
{: refdef}

> RSNs and task networks (left side and right side of each panel, respectively) using [HCP data](http://www.humanconnectomeproject.org/) that correspond to the ten rest/task networks reported in [Smith et al](https://www.pnas.org/content/106/31/13040.short). Networks are shown in red-yellow(+)/blue-light blue(−), thresholded Z = 3.0. Networks are: (1) medial visual, (2) occipital pole, (3) lateral occipital, (4) default mode, (5) cerebellum, (6) sensorimotor, (7) auditory, (8) executive control, (9) right frontoparietal, and (10) left frontoparietal. Taken from [this paper](https://www.nature.com/articles/s41598-018-35209-6).

This project revolved around identifying a biomarker of cognitive decline in aging. The brain's "default mode" network is often associated with introspection, or the maintenance of the a gestalt representation of your own place within a broader context (both spatially and temporally). [This paper](https://pubmed.ncbi.nlm.nih.gov/27424918/) is the best demonstration I have seen of this fact: [Christopher Honey](http://www.honeylab.org/) showed people narratives scrambled at the word, sentence, and paragraph level, and found that the default mode network comes more into play the longer the coherent temporal sequence shown to the participants. In contract the "executive control" network is associated with planning, action, and inhibiting impulses: it is associated with the kind of long-term planning that is responsible for the anthropocene, and its malfunction is associated with [attention impairments](https://www.sciencedirect.com/science/article/abs/pii/S0010945215003068) and [cognitive decline in old age](https://pubmed.ncbi.nlm.nih.gov/24583406/). Interestingly, these two networks counteract one another, which was causally shown using (transcranial magnetic stimulation)[https://www.pnas.org/content/110/49/19944], which led some to believe that this push-pull mechanism between the executive control network and the default mode network was important for proper executive function.

We collected resting state and task-derived BOLD signals from older and younger participants to see whether there was a systematic difference in the functional connectivity between a set of default mode and executive control regions. The [main result](https://www.sciencedirect.com/science/article/abs/pii/S0197458016300896) is presented below: older patients showed significant crosstalk between the two networks, whereas in younger people the push-pull dynamic was intact.

{:refdef: style="text-align: center;"}
![Old Brains, Crossed Wires]({{ '/assets/img/rest/old-vs-young.png' | relative_url }})
{: refdef}

# Neural Networks for Alzheimer's Disease Progression

Using Siamese Networks, we were able to use a cocktail of MRI scans and gene sequences to predict people who were in most need of future clinical care.

While working at the [Centre for Addiction and Mental Health](https://www.camh.ca/), I had the pleasure of working with [Jon Pipitone](https://scholar.google.com/citations?user=SoMyf3YAAAAJ&hl=en&oi=ao), a computer scientist and climate activist trained at the University of Toronto, and [Nikhil Bhagwat](https://dblp.org/pid/67/8968.html), a defense contractor-turned-biomedical researcher, during my day job keeping the lights on at the [Kimel-Family Translational Imaging-Genetics Lab (TIGRLAB)](http://imaging-genetics.camh.ca/), headed by the now-VP of CAMH research, [Dr. Aristotle Voineskos](https://www.camh.ca/en/science-and-research/science-and-research-staff-directory/aristotlevoineskos). In the field, there was a growing consensus that machine learning was a key to improving psychatric diagnosis and treatment, due to the high variability of outcomes given similar diagnosis using traditional tools like the Diagnostics and Statistical Manual of Mental Disorders ([DSM](https://www.psychiatry.org/psychiatrists/practice/dsm)).

{:refdef: style="text-align: center;"}
![Alzheimer's Disease Progression]({{ '/assets/img/trajectories/alz-progression.jpg' | relative_url }})
{: refdef}

The specific problem we wanted to tackle was the detection of the onset of cognitive decline leading to Alzheimer's disease, using the ADNI [Alzheimer's Disease Neuroimaging Initiative](http://adni.loni.usc.edu/) dataset. Being able to do this can be pretty impactful: no treatment can currently reduce the course of Alzheimer's progression, but many treatments can delay the [progression of the disease if it is caught early](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6935598/). This dataset contains MRI scans, SNP hits from blood draws, and cognitive scores over multiple timepoints for many older individual. The cognitive scores allowed us to identify multiple "cognitive trajectories" in the dataset by clustering the two subscales: the "Mini Mental State Exam (MMSE)" and the "Alzheimer's Disease Assessment Scale" (ADAS-13). From both scales, we found a subset of individuals that did not experience substantial decline. Using MMSE, we also found a distinct subset that experienced decline, and for ADAS-13, we found two decliner groups, with one group declining more rapidly.

{:refdef: style="text-align: center;"}
![Identified Trajectories]({{ '/assets/img/trajectories/trajectories.png' | relative_url }})
{: refdef}

Having defined our groups, we then calculated cortical thickness measures from the MRI scans. This measures the thickness of the grey matter across the cortical sheet of the brain: the thickness of the cortex at different regions of the cortex is [associated with differing densities of glial in those regions](https://www.pnas.org/content/110/4/1488), the [ability of the region to integrate signals to be set to other regions](<https://www.cell.com/neuron/fulltext/S0896-6273(18)30956-5>), is known to vary across individuals with different neurological disorders, and has high test-retest reliability due to the stability of the signal (unlike fMRI, which is much more susceptible to the patient's cognitive state and other sources of noise).

{:refdef: style="text-align: center;"}
![Cortical Thickness]({{ '/assets/img/trajectories/thickness.png' | relative_url }})
{: refdef}

Since we wanted to predict decline, we fed pairs of images from adjacent timepoints into a Siamese network, which allowed us to learn a distance embedding that represented the difference between the brain scans over time. Siamese networks are cool because they allow you to input two images of the same modality to calculate some kind of "task-dependent difference metric". This is far less fragile than calculating the differences between the data in the input space. We incorporated genetic information into the prediction by multiplying this embedding by the APOE4 status of the individual: this gene variant is associated with the [development of Alzheimer's disease and disease progression at an earlier age](https://www.alz.org/alzheimers-dementia/what-is-alzheimers/causes-and-risk-factors/genetics).

{:refdef: style="text-align: center;"}
![Model Overview]({{ '/assets/img/trajectories/overview.png' | relative_url }})
{: refdef}

The results of the study were clear: adding a second time-point made trajectory prediction far easier for all models, and the use of Siamese networks to build a distance embedding outperformed all other baselines tested. I'm proud of this work because, while it didn't produce a model that was immediately clinically useful, we laid the groundwork for combining multiple clinically-meaningful biological signals with a longitudinal framework for modeling disease progression, and I believe this general direction will lead to useful future diagnostics (especially if we can get the cost of an MRI scan down to the level where routine screening would be feasible).

For all of the details, see [the full paper here.](https://journals.plos.org/ploscompbiol/article?rev=2&id=10.1371/journal.pcbi.1006376).

# Biotypes of Schizophrenia

Machine learning can be used to find neurologically-distinct subtypes of Schizophrenia.

A major issue with psychiatry is that individuals with the same diagnostic label from the [Diagnostic and Statistical Manual of Mental Disorders (DSM)](https://www.psychiatry.org/psychiatrists/practice/dsm) can actually have very different symptoms or deficits: it is common to count symptoms, and then give a diagnosis if the patient reaches passes a "symptom threshold" (this is an oversimplification, but suffices for illustration). You can imagine that using this scheme, two individuals with the exact same diagnosis might have very few overlapping, or in extreme cases, no overlapping symptoms. This is particularly true with one of the most heterogeneous disorders: Schizophrenia.

Schizophrenia has many subtypes, and it [isn't clear that it is one disease](https://ajp.psychiatryonline.org/doi/10.1176/appi.ajp.2014.14040435). Simultaneously with the project on predicting disease trajectory for those at risk of developing Alzheimer's disease, I was helping the lab manage the [Social Processes Initiative in Neurobiology of the Schizophrenia's (SPINS)](https://academic.oup.com/schizophreniabulletin/article/45/Supplement_2/S144/5434549) study. During my 4 years at the [Centre for Addiction and Mental Health](https://www.camh.ca/en/science-and-research/institutes-and-centres/campbell-family-mental-health-research-institute/research-focus-campbell-institute/kimel-family-translational-imaging-genetics-lab), I spent a lot of my time managing the MRI and clinical data collected by the the three hospitals involved in the study. Briefly, the study was designed to explore the neurological underpinnings of social processing deficits seen in some subtypes of schizophrenia. There's some evidence that the best treatment for Schizophrenia depends on the symptoms, or the subtype, and the optimal treatment varies a lot between individuals. These patterns are largely true for all psychiatric disorders, which led to the [Research Domain Criterion (RDoC)](https://www.nimh.nih.gov/research/research-funded-by-nimh/rdoc/about-rdoc.shtml) framework for mapping genomics and neurological information like brain circuits to behavioural measures in order to generate novel data-driven groups. The underlying goal of the research direction is to understand the brain-behaviour relationships across diseases, to potentially identify neurologically-distinct subtypes of each disease that might be more indicative of the appropriate treatment than the diagnostic label.

{:refdef: style="text-align: center;"}
![RDoC Approach]({{ '/assets/img/biotype/rdoc.png' | relative_url }})
{: refdef}

In my final year with the team, I ran a preliminary study using the data to evaluate the relationships between the fMRI data collected during the study and the behavioural scores. We focused on social processing scores because they are strong predictors of "functional outcomes": how well a schizophrenia patient will recover with treatment. Here, social processing includes things like understanding the emotional state or intentions of someone else, things we call [theory of mind](https://www.nature.com/articles/pr92011100) or [empathy](https://www.sciencedirect.com/science/article/pii/S2352154617301031).

Psychiatric studies are normally conducted by comparing cases (those who meet some DSM criteria) with controls (those who are "healthy", i.e., don't meet any DSM criteria). These case-control studies will compare two groups to determine the features that are somehow unique to a disorder. However, we knew that many individuals with schizophrenia have social processing that are similar to healthy controls, and that simultaneously this deficit predicted poor treatment outcomes. This study sought to find subtypes in our sample _regardless of diagnosis_, by pooling our patients and controls and finding natural groupings of the data based on features derived from both brain connectivity estimates and behavioural scores. We called these subtypes "biotypes".

The method employed was straightforward. Due to the small sample sizes, we decided to learn a low-dimensional representation of both the brain connectivity data and the behavioural scores using principal components analysis, and then found pairs of components that were strongly correlated across patients (this approach is known as [canonical correlation analysis](https://online.stat.psu.edu/stat505/book/export/html/682)). These correlated components, which we can call "canonical variates", were only retained if they were robust in the training set, which we evaluated using cross-validation. The robust canonical variates were finally clustered to generate groups with distinct neuro-behavioural profiles, regardless of diagnosis.

The results were quite striking. A majority of the subjects formed a "normally performing group", comprised of about almost all of the healthy controls and about half of the patients with schizophrenia. In this group, the behavioural and functional outcome scores of interest were high _regardless of diagnosis_. The rest of the patients formed a "poorly performing biotype", and performed significantly worse on these behavioural and functional outcome tests. The difference in these functional outcome scores using a case-control comparison was much smaller than observed when forming the groups according to our biotypes, even though the functional outcome scores were not used at all to derive these new groups.

{:refdef: style="text-align: center;"}
![Biotype Scores]({{ '/assets/img/biotype/scores.png' | relative_url }})
{: refdef}

What was also quite interesting was the neurological differences between these groups. The regions in red (below) are regions with _heightened_ connectivity in the normally-performing biotype, including many subcortical regions with extensive connectivity with frontal regions required to understand others intentions. On the other hand, the blue regions are areas with heightened connectivity in the poorly-performing biotype: these regions are primarily considered early-stage visual processing regions, with less importance in high-order cognitive processes such as understanding the intent of others. A speculative, but interesting, reason for all of this might be that schizophrenia arises from [synaptic pruning gone haywire](https://www.nature.com/articles/nature16549). It is normal and healthy for the brain to remove connections as it develops so that only the most useful and efficient ones survive, and if this process is abnormal, it could lead to abnormal functional connectivity profiles. Crucially, this process might happen differently for each patient afflicted with schizophrenia, and this might leave behind a unique signature that can be used to determine the ideal treatment for each patient.

{:refdef: style="text-align: center;"}
![Biotype Connectivity]({{ '/assets/img/biotype/biotypes.png' | relative_url }})
{: refdef}

While our study raises just as many questions as it answers, I do think that the general framework is a useful path forward for transitioning away from the DSM, and I am proud of that contribution. You can read [the whole paper here](https://www.sciencedirect.com/science/article/abs/pii/S0006322318314392).

Soon after this work was published, I moved to Montreal, to study machine learning at the University of Montreal and Mila.
